name: Global Parquet Converter
on:
  push:
    branches: [ "main", "master" ]
  workflow_dispatch:

jobs:
  convert:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      
    steps:
      - name: 1. كودلارنى يۈكلەش
        uses: actions/checkout@v4

      - name: 2. Python تەييارلاش
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: 3. قوراللارنى قاچىلاش
        run: pip install pandas pyarrow fastparquet PyYAML

      - name: 4. مەلۇماتلارنى سۈزۈپ جەملەش
        run: |
          python -c "
          import pandas as pd
          import os
          import glob
          import yaml

          # Articles ئىچىدىكى ماقالىلەرنى جەملەش
          md_files = glob.glob('Articles/**/*.md', recursive=True)
          articles_data = []
          
          for f in md_files:
              try:
                  with open(f, 'r', encoding='utf-8') as file:
                      content = file.read()
                      
                      # YAML Front Matter بۆلىكىنى ئايرىۋېلىش
                      if content.startswith('---'):
                          parts = content.split('---', 2)
                          if len(parts) >= 3:
                              header = yaml.safe_load(parts[1])
                              body = parts[2].strip()
                              
                              author = header.get('author', 'Unknown')
                              date = header.get('date', 'Unknown')
                              title = header.get('title', os.path.basename(f).replace('.md', ''))
                              
                              articles_data.append({'title': title, 'author': author, 'date': str(date), 'text': body, 'source': f})
                              continue
                      
                      title = os.path.basename(f).replace('.md', '')
                      articles_data.append({'title': title, 'author': 'Unknown', 'date': 'Unknown', 'text': content.strip(), 'source': f})
                      
              except Exception as e:
                  print(f'❌ MD ئوقۇش خاتالىقى {f}: {e}')
          
          if articles_data:
              df_articles = pd.DataFrame(articles_data)
              df_articles.to_parquet('articles_corpus.parquet', engine='pyarrow', index=False)
              print('✅ يېڭى ستونلار بىلەن articles_corpus.parquet يېڭىلاندى.')

          # JSONL ھۆججەتلىرىنىمۇ ئايلاندۇرۇش
          for f in glob.glob('**/*.jsonl', recursive=True):
              if '.github' in f: continue
              try:
                  pd.read_json(f, lines=True).to_parquet(f.replace('.jsonl', '.parquet'), engine='pyarrow', index=False)
              except: pass
          "

      - name: 5. ئۆزگىرىشنى يوللاش (GitHub & Hugging Face)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          # Parquet ھۆججەتلىرىنى قوشۇش
          find . -name "*.parquet" -exec git add {} +
          git commit -m "Auto-update: Parquet files and metadata" || echo "No changes to commit"
          
          # 1. ئالدى بىلەن GitHub نى يېڭىلاش
          git push origin main
          
          # 2. ئاندىن Hugging Face غا ماس قەدەملەش
          # ئىشلەتكۈچى_ئىسمى/تۈر_ئىسمى نى ئۆزگەرتىشنى ئۇنۇتماڭ
          git remote add hf https://x-access-token:$HF_TOKEN@huggingface.co/datasets/ئىشلەتكۈچى_ئىسمى/تۈر_ئىسمى || true
          git push hf main --force

      # --- يېڭى قوشۇلغان قىسىم: Hugging Face نىڭ ئاپتوماتىك ئايلاندۇرۇش ئىقتىدارىنى قوزغىتىش ---
      - name: 6. Hugging Face ئاپتوماتىك ئايلاندۇرۇشنى قوزغىتىش
        run: |
          curl -X POST https://huggingface.co/api/datasets/ئىشلەتكۈچى_ئىسمى/تۈر_ئىسمى/webapp-restart \
          -H "Authorization: Bearer ${{ secrets.HF_TOKEN }}"
